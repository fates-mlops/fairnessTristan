{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9635afb4",
   "metadata": {},
   "source": [
    "Chargement des données et préparation des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "INPUT_FOLDER = '../1_data/1_raw/'\n",
    "\n",
    "OUTPUT_FOLDER = '../1_data/2_preprocessed/'\n",
    "\n",
    "dataset = pd.read_csv(INPUT_FOLDER + 'adult_census_income.csv')\n",
    "\n",
    "# On ne souhaite pas utiliser la colonne 'race'\n",
    "dataset = dataset.drop(columns='race')\n",
    "\n",
    "# la colonne fnlwgt (final weight) représente la pondération des individus dans la population.\n",
    "# Cette variable ne doit jamais être utilisée pour l'entrainement d'un modèle, elle ne décrit pas l'individu. \n",
    "# Cette variable devrait être prise en compte comme poids dans l'entrainement d'un modèle.\n",
    "# Ici, on ne souhaite que consider les variables sur lesquelles le modèle apprend. On peut donc la retirer.\n",
    "dataset = dataset.drop(columns='fnlwgt')\n",
    "\n",
    "# Il existe deux variables pour qualifier le niveau d'études : education et education.num.\n",
    "# Elles sont équivalentes mais la première n'est pas numérique, on conserve donc la seconde.\n",
    "dataset = dataset.drop(columns='education')\n",
    "\n",
    "# Les variables capital.gain et capital.loss indiquent tous les deux une variation du capital (investissement) mais en positif et en négatif. \n",
    "# On peut simplifier ces deux features en une seule.\n",
    "dataset['capital_diff'] = dataset['capital.gain'] - dataset['capital.loss']\n",
    "dataset = dataset.drop(columns=['capital.gain', 'capital.loss'])\n",
    "\n",
    "# Les valeurs manquantes sont remplacées par des \"Unknown\"\n",
    "dataset.replace('?', pd.NA, inplace=True)\n",
    "for col in dataset.columns:\n",
    "    dataset[col] = dataset[col].fillna('Unknown')\n",
    "\n",
    "# Transformation des variables qualitatives en variables numériques (one-hot encoding).\n",
    "# workclass, marital.status, occupation, relationship, sex, native.country, income.\n",
    "# sex et income sont binaires, les autres multiclasse.\n",
    "dataset['sex'] = dataset.sex == 'Male'\n",
    "dataset['income'] = dataset.income == '>50K'\n",
    "dataset = pd.get_dummies(dataset, columns=['workclass', 'marital.status', 'occupation', 'relationship', 'native.country'])\n",
    "\n",
    "# On transforme les colonnes de type int en type float pour éviter les erreurs en cas de valeur manquante à l'avenir\n",
    "int_cols = dataset.select_dtypes(include=\"int\").columns\n",
    "dataset[int_cols] = dataset[int_cols].astype(\"float64\")\n",
    "\n",
    "# On enregistre le jeu de donnée préparé.\n",
    "dataset.to_csv(OUTPUT_FOLDER + 'x0.csv')\n",
    "x0_param = {\n",
    "    'sample_name' : 'x0',\n",
    "    'sample_strategy': None,\n",
    "}\n",
    "with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(x0_param, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311695d2",
   "metadata": {},
   "source": [
    "On souhaite ensuite créer des échantillons biaisés.\n",
    "\n",
    "Pour les construire, on va classer les individus dans des strates selon \"sex\" et \"income\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c81a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strate\n",
       "True_False     15128\n",
       "False_False     9592\n",
       "True_True       6662\n",
       "False_True      1179\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['strate'] = dataset['sex'].astype(str) + '_' + dataset['income'].astype(str)\n",
    "dataset['strate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839c516",
   "metadata": {},
   "source": [
    "Création de huit échantillons :\n",
    "\n",
    "Le premier est une simple réduction du jeu de données, les autres sont construit pour créer des situations de fairness à partir des trois critères suivant :\n",
    "* (a) : Equilibrer la variable \"sex\"\n",
    "* (b) : Equilibrer la variable \"income\"\n",
    "* (c) : Equilibrer les proportions \"sex\"/\"income\" (Homme>50k / Homme<=50k = Femme>50k / Femme<=50k)\n",
    "\n",
    "Afin de pouvoir comparer des modèles de machine learning entrainés sur ces échantillons, on pose une taille de 4000 pour chacun d'entre eux.\n",
    "\n",
    "Ci-dessous ces huits échantillons présentés sous la forme d'un tableau d'effectifs :\n",
    "\n",
    "X1\n",
    "\n",
    "![X1](img/x1.jpg)\n",
    "\n",
    "A noter, X1 n'est pas vraiment représentatif du dataset adult income car nous avons retiré les pondérations fnlwgt.\n",
    "\n",
    "X2\n",
    "\n",
    "![X2](img/x2.jpg)\n",
    "\n",
    "X3\n",
    "\n",
    "![X3](img/x3.jpg)\n",
    "\n",
    "X4\n",
    "\n",
    "![X4](img/x4.jpg)\n",
    "\n",
    "X5\n",
    "\n",
    "![X5](img/x5.jpg)\n",
    "\n",
    "X6\n",
    "\n",
    "![X6](img/x6.jpg)\n",
    "\n",
    "X7\n",
    "\n",
    "![X7](img/x7.jpg)\n",
    "\n",
    "X8\n",
    "\n",
    "![X8](img/x8.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850fce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(data, minf, finf, msup, fsup):\n",
    "    strates = {\n",
    "        'True_False': minf,\n",
    "        'False_False': finf,\n",
    "        'True_True': msup,\n",
    "        'False_True': fsup\n",
    "    }\n",
    "    X = []\n",
    "    for strate, size in strates.items():\n",
    "        group = data[data['strate'] == strate]\n",
    "        if len(group) < size:\n",
    "            raise ValueError(f\"Pas assez d'observations dans la strate {strate} (dispo: {len(group)}, demandé: {size})\")\n",
    "        X.append(group.sample(n=size, random_state=1))\n",
    "    X = pd.concat(X).reset_index(drop=True)\n",
    "    X = X.drop(columns='strate')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1_param = {\n",
    "#     'sample_name' : 'x1',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 1859,\n",
    "#         'female_<=50k' : 1178,\n",
    "#         'male_>50k' : 818,\n",
    "#         'female_>50k' : 145,\n",
    "#     }\n",
    "# }\n",
    "# X1 = sample(dataset, 1859, 1178, 818, 145)\n",
    "# x2_param = {\n",
    "#     'sample_name' : 'x2',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 1400,\n",
    "#         'female_<=50k' : 1600,\n",
    "#         'male_>50k' : 600,\n",
    "#         'female_>50k' : 400,\n",
    "#     }\n",
    "# }\n",
    "# X2 = sample(dataset, 1400, 1600, 600, 400)\n",
    "# x3_param = {\n",
    "#     'sample_name' : 'x3',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 1300,\n",
    "#         'female_<=50k' : 700,\n",
    "#         'male_>50k' : 1700,\n",
    "#         'female_>50k' : 300,\n",
    "#     }\n",
    "# }\n",
    "# X3 = sample(dataset, 1300, 700, 1700, 300)\n",
    "# x4_param = {\n",
    "#     'sample_name' : 'x4',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 2031,\n",
    "#         'female_<=50k' : 1005,\n",
    "#         'male_>50k' : 645,\n",
    "#         'female_>50k' : 319,\n",
    "#     }\n",
    "# }\n",
    "# X4 = sample(dataset, 2031, 1005, 645, 319)\n",
    "# x5_param = {\n",
    "#     'sample_name' : 'x5',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 800,\n",
    "#         'female_<=50k' : 1200,\n",
    "#         'male_>50k' : 1200,\n",
    "#         'female_>50k' : 800,\n",
    "#     }\n",
    "# }\n",
    "# X5 = sample(dataset, 800, 1200, 1200, 800)\n",
    "# x6_param = {\n",
    "#     'sample_name' : 'x6',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 1500,\n",
    "#         'female_<=50k' : 1500,\n",
    "#         'male_>50k' : 500,\n",
    "#         'female_>50k' : 500,\n",
    "#     }\n",
    "# }\n",
    "# X6 = sample(dataset, 1500, 1500, 500, 500)\n",
    "# x7_param = {\n",
    "#     'sample_name' : 'x7',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 1300,\n",
    "#         'female_<=50k' : 700,\n",
    "#         'male_>50k' : 1300,\n",
    "#         'female_>50k' : 700,\n",
    "#     }\n",
    "# }\n",
    "# X7 = sample(dataset, 1300, 700, 1300, 700)\n",
    "# x8_param = {\n",
    "#     'sample_name' : 'x8',\n",
    "#     'sample_strategy': {\n",
    "#         'male_<=50k' : 1000,\n",
    "#         'female_<=50k' : 1000,\n",
    "#         'male_>50k' : 1000,\n",
    "#         'female_>50k' : 1000,\n",
    "#     }\n",
    "# }\n",
    "# X8 = sample(dataset, 1000, 1000, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e156a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1.to_csv(OUTPUT_FOLDER + 'x1.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x1_param, f, indent=4, ensure_ascii=False)\n",
    "# X2.to_csv(OUTPUT_FOLDER + 'x2.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x2_param, f, indent=4, ensure_ascii=False)\n",
    "# X3.to_csv(OUTPUT_FOLDER + 'x3.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x3_param, f, indent=4, ensure_ascii=False)\n",
    "# X4.to_csv(OUTPUT_FOLDER + 'x4.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x4_param, f, indent=4, ensure_ascii=False)\n",
    "# X5.to_csv(OUTPUT_FOLDER + 'x5.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x5_param, f, indent=4, ensure_ascii=False)\n",
    "# X6.to_csv(OUTPUT_FOLDER + 'x6.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x6_param, f, indent=4, ensure_ascii=False)\n",
    "# X7.to_csv(OUTPUT_FOLDER + 'x7.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x7_param, f, indent=4, ensure_ascii=False)\n",
    "# X8.to_csv(OUTPUT_FOLDER + 'x8.csv')\n",
    "# with open(OUTPUT_FOLDER + \"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(x8_param, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc57cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
